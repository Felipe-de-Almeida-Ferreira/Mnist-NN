{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import csv\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ATIVAÇÕES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x, derivative=False):\n",
    "    return np.ones_like(x) if derivative else x\n",
    "\n",
    "def sigmoid(x, derivative=False):\n",
    "    if derivative:\n",
    "        y = sigmoid(x)\n",
    "        return y*(1 - y)\n",
    "    return 1.0/(1.0 + np.exp(-x))\n",
    "\n",
    "def tanh(x, derivative=False):\n",
    "    if derivative:\n",
    "        y = tanh(x)\n",
    "        return 1 - y**2\n",
    "    return (np.exp(x) - np.exp(-x))/(np.exp(x) + np.exp(-x))\n",
    "\n",
    "def relu(x, derivative=False):\n",
    "    if derivative:\n",
    "        return np.where(x <= 0, 0, 1)\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def leaky_relu(x, derivative=False):\n",
    "    alpha = 0.1\n",
    "    if derivative:\n",
    "        return np.where(x <= 0, alpha, 1)\n",
    "    return np.where(x <= 0, alpha*x, x)\n",
    "\n",
    "def elu(x, derivative=False):\n",
    "    alpha = 1.0\n",
    "    if derivative:\n",
    "        y = elu(x)\n",
    "        return np.where(x <= 0, y + alpha, 1)\n",
    "    return np.where(x <= 0, alpha*(np.exp(x) - 1), x)\n",
    "\n",
    "\n",
    "\n",
    "def softmax(x, y_oh=None, derivative=False):\n",
    "    if derivative:\n",
    "        y_pred = softmax(x)\n",
    "        k = np.nonzero(y_pred * y_oh)\n",
    "        pk = y_pred[k]\n",
    "        y_pred[k] = pk * (1.0 - pk)\n",
    "        return y_pred\n",
    "    exp = np.exp(x)\n",
    "    return exp / np.sum(exp, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUNÇÕES DE CUSTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy(y, y_pred, derivative=False):\n",
    "    if derivative:\n",
    "        return -(y - y_pred) / (y_pred * (1 - y_pred) * y.shape[0])\n",
    "    return -(np.mean(y*np.log(y_pred) + (1 - y)*(np.log(1 - y_pred))))\n",
    "\n",
    "def sigmoid_cross_entropy(y, y_pred, derivative=False):\n",
    "    y_sigmoid = sigmoid(y_pred)\n",
    "    if derivative:\n",
    "        -(y - y_sigmoid) / y.shape[0]\n",
    "    return -(np.mean(y*np.log(y_sigmoid) + (1 - y)*(np.log(1 - y_sigmoid))))\n",
    "\n",
    "def neg_log_likelihood(y_oh, y_pred, derivative=False):\n",
    "    k = np.nonzero(y_pred * y_oh)\n",
    "    pk = y_pred[k]\n",
    "    if derivative:\n",
    "        y_pred[k] = (-1.0 / pk)\n",
    "        return y_pred\n",
    "    return np.mean(-np.log(pk))\n",
    "\n",
    "def softmax_neg_log_likelihood(y_oh, y_pred, derivative=False):\n",
    "    y_softmax = softmax(y_pred)\n",
    "    if derivative:\n",
    "        return -(y_oh - y_softmax) / y_oh.shape[0]    \n",
    "    return neg_log_likelihood(y_oh, y_softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INICIALIZAÇÕES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeros(rows, cols):\n",
    "    return np.zeros((rows, cols))\n",
    "\n",
    "def ones(rows, cols):\n",
    "    return np.ones((rows, cols))\n",
    "\n",
    "def random_normal(rows, cols):\n",
    "    return np.random.randn(rows, cols)\n",
    "\n",
    "def random_uniform(rows, cols):\n",
    "    return np.random.rand(rows, cols)\n",
    "\n",
    "def glorot_normal(rows, cols):\n",
    "    std_dev = np.sqrt(2.0 / (rows + cols))\n",
    "    return std_dev * np.random.randn(rows, cols)\n",
    "\n",
    "def glorot_uniform(rows, cols):\n",
    "    limit = np.sqrt(6.0 / rows + cols)\n",
    "    return 2 * limit * np.random.rand(rows, cols) - limit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer():\n",
    "    def __init__(self, input_dim, output_dim, weights_initializer=random_normal, bias_initializer=ones, activation=linear):\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.weights = weights_initializer(output_dim, input_dim)\n",
    "        self.biases = bias_initializer(1, output_dim)\n",
    "        self.activation = activation\n",
    "\n",
    "\n",
    "        self._activ_inp, self._activ_out = None, None\n",
    "        self._dweights, self._dbiases, self._prev_dweights = None, None, 0.0\n",
    "\n",
    "class NeuralNetwork():\n",
    "    def __init__(self, cost_func=sigmoid_cross_entropy, learning_rate=1e-3):\n",
    "        self.layers = []\n",
    "        self.cost_func = cost_func\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def fit(self, x_train, y_train, epochs=100, verbose=10):\n",
    "        for epoch in range(epochs + 1):\n",
    "            y_pred = self.__feedforward(x_train)\n",
    "            self.__backprop(y_train, y_pred)\n",
    "\n",
    "            if epoch % verbose == 0:\n",
    "                loss_train = self.cost_func(y_train, self.predict(x_train))\n",
    "                print(\"epochs: {0:=4}/{1} loss_train: {2:.8f}\".format(epoch, epochs, loss_train))\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.__feedforward(x)\n",
    "\n",
    "    def save(self, file_path):\n",
    "        pkl.dump(self, open(file_path, 'wb'), -1)\n",
    "\n",
    "    def load(file_path):\n",
    "        return pkl.load(open(file_path, 'rb'))\n",
    "\n",
    "    def __feedforward(self, x):\n",
    "        self.layers[0].input = x\n",
    "        for current_layer, next_layer in zip(self.layers, self.layers[1:] + [Layer(0, 0)]):\n",
    "            y = np.dot(current_layer.input, current_layer.weights.T) + current_layer.biases\n",
    "            current_layer._activ_inp = y\n",
    "            current_layer._activ_out = next_layer.input = current_layer.activation(y)\n",
    "        return self.layers[-1]._activ_out\n",
    "\n",
    "\n",
    "    def __backprop(self, y, y_pred):\n",
    "        last_delta = self.cost_func(y, y_pred, derivative=True)\n",
    "        for layer in reversed(self.layers):\n",
    "            dactivation = layer.activation(layer._activ_inp, derivative=True) * last_delta\n",
    "            last_delta = np.dot(dactivation, layer.weights)\n",
    "            layer._dweights = np.dot(dactivation.T, layer.input)\n",
    "            layer._dbiases = 1.0 * dactivation.sum(axis=0, keepdims=True)\n",
    "\n",
    "        for layer in reversed(self.layers):\n",
    "            layer.weights = layer.weights - self.learning_rate * layer._dweights\n",
    "            layer.biases = layer.biases - self.learning_rate * layer._dbiases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001\n"
     ]
    }
   ],
   "source": [
    "#train_data = pd.read_csv(\"mnist_train.csv\")\n",
    "#test_data = pd.read_csv(\"mnist_test.csv\")\n",
    "#data.head()\n",
    "\n",
    "with open(\"mnist_train.csv\") as train_data:\n",
    "    train_list = list(itertools.islice(train_data, 1001))\n",
    "\n",
    "'''test_data = open(\"mnist_test.csv\")\n",
    "test_list = test_data.readlines()\n",
    "test_data.close()'''\n",
    "\n",
    "print(len(train_list))\n",
    "#print(len(test_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784 1\n",
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x, y = [], []\n",
    "\n",
    "for line in train_list[1:]:\n",
    "    values = line.split(\",\")\n",
    "    label = int(values[0])\n",
    "\n",
    "    image_array = np.asfarray(values[1:]).reshape((28,28))\n",
    "    \n",
    "    x.append(image_array.flatten())\n",
    "    y.append(label)\n",
    "\n",
    "    #plt.figure()\n",
    "    #plt.imshow(image_array, cmap=\"Greys\", interpolation=\"None\")\n",
    "    #plt.show()\n",
    "\n",
    "x = np.asarray(x)\n",
    "y = np.asarray(y).reshape(-1, 1)\n",
    "'''\n",
    "for line in train_list[1:]:\n",
    "    values = line.split(\",\")\n",
    "    label = int(values[0])\n",
    "    image_data = np.from\n",
    "    '''\n",
    "\n",
    "print(x.shape[1], y.shape[1])\n",
    "\n",
    "onehot = OneHotEncoder(sparse_output=False)\n",
    "y_onehot = onehot.fit_transform(y)\n",
    "print(y_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs:    0/2000 loss_train: 7.28152877\n",
      "epochs:  100/2000 loss_train: 0.94241211\n",
      "epochs:  200/2000 loss_train: 0.65877043\n",
      "epochs:  300/2000 loss_train: 0.59761902\n",
      "epochs:  400/2000 loss_train: 0.57948836\n",
      "epochs:  500/2000 loss_train: 0.53215861\n",
      "epochs:  600/2000 loss_train: 0.51020475\n",
      "epochs:  700/2000 loss_train: 0.48985869\n",
      "epochs:  800/2000 loss_train: 0.47023204\n",
      "epochs:  900/2000 loss_train: 0.45443601\n",
      "epochs: 1000/2000 loss_train: 0.43968452\n",
      "epochs: 1100/2000 loss_train: 0.42642941\n",
      "epochs: 1200/2000 loss_train: 0.41597031\n",
      "epochs: 1300/2000 loss_train: 0.40531628\n",
      "epochs: 1400/2000 loss_train: 0.39359709\n",
      "epochs: 1500/2000 loss_train: 0.38566780\n",
      "epochs: 1600/2000 loss_train: 0.37770999\n",
      "epochs: 1700/2000 loss_train: 0.36992751\n",
      "epochs: 1800/2000 loss_train: 0.36041656\n",
      "epochs: 1900/2000 loss_train: 0.35188024\n",
      "epochs: 2000/2000 loss_train: 0.34543694\n",
      "Acurácia: 91.80%\n"
     ]
    }
   ],
   "source": [
    "input_dim, output_dim = x.shape[1], y_onehot.shape[1]\n",
    "\n",
    "nn = NeuralNetwork(cost_func=softmax_neg_log_likelihood, learning_rate=1e-2)\n",
    "nn.layers.append(Layer(input_dim=input_dim, output_dim=64, activation=sigmoid, weights_initializer=glorot_normal))\n",
    "nn.layers.append(Layer(input_dim=64, output_dim=64, activation=sigmoid))\n",
    "nn.layers.append(Layer(input_dim=64, output_dim=64, activation=sigmoid))\n",
    "nn.layers.append(Layer(input_dim=64, output_dim=output_dim, activation=linear))\n",
    "\n",
    "nn.fit(x, y_onehot, epochs=2000, verbose=100)\n",
    "\n",
    "nn.save('modelnpNN.pkl')\n",
    "\n",
    "y_pred = np.argmax(nn.predict(x), axis=1)\n",
    "print('Acurácia: {:.2f}%'.format(100*accuracy_score(y, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_image():\n",
    "    with open('mnist_test.csv') as test:\n",
    "        reader = csv.reader(test)\n",
    "        chosen_row = random.choice(list(reader))\n",
    "    return chosen_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    row = random_image()\n",
    "    #print(row)\n",
    "\n",
    "    tlabel = int(row[0])\n",
    "    test_image_array =  np.asfarray(row[1:]).reshape((28, 28))\n",
    "    #print(test_image_array)\n",
    "    print(\"Image:\")\n",
    "    plt.figure()\n",
    "    plt.imshow(test_image_array, cmap=\"Greys\", interpolation=\"None\")\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"\\nLabel: {tlabel}\")\n",
    "\n",
    "    x, y = [], []\n",
    "\n",
    "    x.append(test_image_array.flatten())\n",
    "    y.append(tlabel)\n",
    "\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y).reshape(-1, 1)\n",
    "\n",
    "    #print(x.shape[1], y.shape[1])\n",
    "\n",
    "    onehot = OneHotEncoder(sparse_output=False)\n",
    "    y_onehot = onehot.fit_transform(y)\n",
    "    #print(y_onehot)\n",
    "\n",
    "    nn = NeuralNetwork.load('modelnpNN.pkl')\n",
    "    predicted_class = np.argmax(nn.predict(x), axis=1)\n",
    "\n",
    "    print(f\"predict: {predicted_class}\")\n",
    "\n",
    "    if tlabel == predicted_class:\n",
    "        print(\"\\033[1;32mPREDICTION CORRECT\")\n",
    "    else:\n",
    "        print(\"\\033[1;31mPREDICTION ICORRECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label: 2\n",
      "predict: [2]\n",
      "\u001b[1;32mPREDICTION CORRECT\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mpdl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
